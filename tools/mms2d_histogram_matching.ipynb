{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from tqdm.notebook import tqdm\n",
    "import plotly\n",
    "import plotly.figure_factory as ff\n",
    "import numpy as np\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils.datasets import *\n",
    "from utils.data_augmentation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import match_histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset pixel values distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(vendor, normalization=\"standardize\", data_mod=\"\", verbose=False):\n",
    "    \n",
    "    data_augmentation = \"none\"\n",
    "    img_size, crop_size = 224, 224 # We will take original image not transformed one\n",
    "    mask_reshape_method = \"padd\"\n",
    "    train_aug, train_aug_img, val_aug = data_augmentation_selector(\n",
    "        data_augmentation, img_size, crop_size, mask_reshape_method, verbose=verbose\n",
    "    )\n",
    "    \n",
    "    add_depth = False\n",
    "    batch_size = 100\n",
    "\n",
    "    dataset = f\"mms_vendor{vendor}{data_mod}\"\n",
    "\n",
    "    only_end = False if \"full\" in dataset else True\n",
    "    unlabeled = True if \"unlabeled\" in dataset else False\n",
    "    c_centre = find_values(dataset, \"centre\", int)\n",
    "    c_vendor = find_values(dataset, \"vendor\", str)\n",
    "\n",
    "\n",
    "    train_dataset = MMs2DDataset(\n",
    "        partition=\"Training\", transform=train_aug, img_transform=train_aug_img, \n",
    "        normalization=normalization, add_depth=add_depth, \n",
    "        is_labeled=(not unlabeled), centre=c_centre, vendor=c_vendor, \n",
    "        end_volumes=only_end, data_relative_path=\"../\"\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, pin_memory=True,\n",
    "        shuffle=False, collate_fn=train_dataset.custom_collate\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Len train_dataset df: {len(train_dataset.data)}\")\n",
    "\n",
    "    img_list = []\n",
    "    for batch_indx, batch in enumerate(train_loader):\n",
    "        for original_img in batch[\"image\"]:\n",
    "            unique, counts = np.unique(original_img, return_counts=True)\n",
    "            img_list.append( original_img.cpu().numpy() )\n",
    "        break\n",
    "    return np.concatenate(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"data_analysis/histogram_matching\"\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list_A = get_data(\"A\", normalization=\"none\")\n",
    "img_list_B = get_data(\"B\", normalization=\"none\")\n",
    "img_list_C = get_data(\"C\", normalization=\"none\", data_mod=\"_unlabeled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_indx in range(25):\n",
    "\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(17, 10))\n",
    "\n",
    "    ax1.imshow(img_list_A[img_indx], cmap=\"gray\")\n",
    "    ax1.axis(\"off\")\n",
    "    ax1.set_title(\"Vendor A\")\n",
    "\n",
    "    ax2.imshow(img_list_B[img_indx], cmap=\"gray\")\n",
    "    ax2.axis(\"off\")\n",
    "    ax2.set_title(\"Vendor B\")\n",
    "\n",
    "    matched = match_histograms(img_list_A[img_indx], img_list_B[img_indx], multichannel=False)\n",
    "\n",
    "    ax3.imshow(matched, cmap=\"gray\")\n",
    "    ax3.axis(\"off\")\n",
    "    ax3.set_title(\"Vendor A Matched to B\")\n",
    "\n",
    "    plt.savefig(\n",
    "        os.path.join(save_dir, f\"AtoB_{uuid.uuid4().hex}.jpg\"), \n",
    "        bbox_inches = 'tight', pad_inches = 0.5, dpi=250\n",
    "    )\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_indx in range(25):\n",
    "\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(17, 10))\n",
    "\n",
    "    ax1.imshow(img_list_B[img_indx], cmap=\"gray\")\n",
    "    ax1.axis(\"off\")\n",
    "    ax1.set_title(\"Vendor B\")\n",
    "\n",
    "    ax2.imshow(img_list_A[img_indx], cmap=\"gray\")\n",
    "    ax2.axis(\"off\")\n",
    "    ax2.set_title(\"Vendor A\")\n",
    "\n",
    "    matched = match_histograms(img_list_B[img_indx], img_list_A[img_indx], multichannel=False)\n",
    "\n",
    "    ax3.imshow(matched, cmap=\"gray\")\n",
    "    ax3.axis(\"off\")\n",
    "    ax3.set_title(\"Vendor B Matched to A\")\n",
    "\n",
    "    plt.savefig(\n",
    "        os.path.join(save_dir, f\"BtoA_{uuid.uuid4().hex}.jpg\"), \n",
    "        bbox_inches = 'tight', pad_inches = 0.5, dpi=250\n",
    "    )\n",
    "    \n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
